{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45014408",
   "metadata": {},
   "source": [
    "<h1><center>27 Day F10.7 Forecast Verification (Jan 2020 - Jul 2023)</center></h1>\n",
    "<br>\n",
    "<center>John Mayers, Physical Scientist <br> NOAA Space Weather Prediction Center</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7d22fb",
   "metadata": {},
   "source": [
    "The Space Weather Prediction Center produces 27 Day geomagnetic and radio forecasts found in the [\"Weekly Highlights and 27-day Forecast\"](https://www.swpc.noaa.gov/products/weekly-highlights-and-27-day-forecast). These forecast are not archived in a database and can only be found in these PDF documents. In order to assess forecast accuracy and skill, the forecasts have to be extracted from these PDF files into a readable format. This fist part of this program will extract the forecasts from the PDF files (found on page 4) using tabula-py then convert them into text files. The text files will then be read into Pandas dataframes for additional analysis. Once cleaned, these forecasts can be compared against observed values in order to obtain accuracy and skill scores. Observed data are archived in a database and have been made available in an .xlsx spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38b6523a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tabula\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "    \n",
    "from tabula.io import read_pdf\n",
    "from tabulate import tabulate\n",
    "from tabula.io import convert_into\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "from numpy import nan\n",
    "from matplotlib.pyplot import figure\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1515312b",
   "metadata": {},
   "source": [
    "<h3>Navigating to files</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881a3e55",
   "metadata": {},
   "source": [
    "**Step 1**: Change the working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "257558db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current working directory is C:\\Users\\john.mayers\\Documents\\27_Day\\Data\\2020_23_WeeklyPDF.\n"
     ]
    }
   ],
   "source": [
    "#change working directory to location of pdf files and set to variable\n",
    "    \n",
    "os.chdir('C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/')\n",
    "directory = 'C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/'\n",
    "print(f'The current working directory is {os. getcwd()}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc42c8f",
   "metadata": {},
   "source": [
    "**Step 2**: Confirm the number of PDF files in the directory to be converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5d4bcb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The are 2 PDF files in this folder.\n"
     ]
    }
   ],
   "source": [
    "pdf_ls = []\n",
    "for file in glob.glob(\"*.pdf\"):\n",
    "    pdf_ls.append(file)\n",
    "pdf_ls\n",
    "\n",
    "num_pdfs = len(pdf_ls)\n",
    "\n",
    "print(f'The are {num_pdfs} PDF files in this folder.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e93a50ac",
   "metadata": {},
   "source": [
    "<h3>Preparing to use tabula-py to convert PDF to TXT</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9085df4",
   "metadata": {},
   "source": [
    "The tabula-py wrapper has a specific format *(convert_into(input_filename, output_filename, pages=all)* to read PDF files and convert to TXT. Since hundreds of PDF files will need to be processed, loops will be needed to iterate through input and output filenames."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7893e9",
   "metadata": {},
   "source": [
    "**Step 1**: Create iterable output filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bde5fc1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2314.txt',\n",
       " 'C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2387.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a list of output_filenames from PDF filenames in dir but with .txt extension\n",
    "\n",
    "filenames = os.listdir() #list all PDF files in folder and save to variable\n",
    "filenames = [i.split('.', 1)[0] for i in filenames] #remove file extension from list of files and resave to variable\n",
    "\n",
    "ls=[]\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    w = os.path.join(directory + filenames[i]+ \".txt\") #concat directory, filenames with .txt extension\n",
    "    ls.append(w)\n",
    "    \n",
    "#ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb535de",
   "metadata": {},
   "source": [
    "**Step 2**: Create iterable input filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8c863b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2314.pdf',\n",
       " 'C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2387.pdf']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a list of input_filenames\n",
    "\n",
    "ls1=[]\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    r = os.path.join(directory + filenames[i]+ \".pdf\") #concat directory, filenames, with .pdf extension\n",
    "    ls1.append(r)\n",
    "\n",
    "#ls1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ede028",
   "metadata": {},
   "source": [
    "<h3>Converting PDF to TXT using tabula-py</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3befd732",
   "metadata": {},
   "source": [
    "**Step 1**: Using tabula-py, iterate through the input and output files created in the previous step to convert PDF files to TXT files. Note each PDF file can take up to 60 seconds to be converted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f667bd64",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [01:26<00:00,  1.42s/it]\n"
     ]
    }
   ],
   "source": [
    "#using tabula-py convert_into() function to convert PDF files in dir to TXT\n",
    "\n",
    "for pdf in tqdm(directory):\n",
    "    for i in range(len(ls)):\n",
    "        convert_into(ls1[i], ls[i], pages=4) #iterating through input and output filenames from lists above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ee288a",
   "metadata": {},
   "source": [
    "**Step 2**: Verify all PDF files were converted to TXT files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59b0126c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All PDF files were successfully converted to TXT files\n"
     ]
    }
   ],
   "source": [
    "#verifying conversion was successful\n",
    "\n",
    "num_txt = len(glob.glob1(directory,\"*.txt\"))\n",
    "\n",
    "if num_pdfs == num_txt:\n",
    "    print(\"All PDF files were successfully converted to TXT files\")\n",
    "else: \n",
    "    print(\"Some PDF files were not successfully converted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a5d8a5",
   "metadata": {},
   "source": [
    "<h3>Converting all TXT files to Pandas Dataframe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "196f0340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prf2314.txt', 'prf2387.txt']\n"
     ]
    }
   ],
   "source": [
    "f=[]\n",
    "\n",
    "for file in os.listdir(directory):\n",
    "    if file.endswith(\".txt\"):\n",
    "        f.append(file)\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca24bd6",
   "metadata": {},
   "source": [
    "Looking at the first couple of TXT files that were converted from the first PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b731964b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "06 Jan,72,12,4,,20 Jan,70,5,2,\n",
      "07,72,5,2,,21,70,5,2,\n",
      "08,72,8,3,,22,70,5,2,\n",
      "09,72,8,3,,23,70,5,2,\n",
      "10,72,8,3,,24,70,5,2,\n",
      "11,72,5,2,,25,71,5,2,\n",
      "12,71,5,2,,26,72,5,2,\n",
      "13,70,5,2,,27,72,5,2,\n",
      "14,70,12,4,,28,72,5,2,\n",
      "15,70,12,4,,29,72,5,2,\n",
      "16,70,5,2,,30,72,5,2,\n",
      "17,70,5,2,,31,72,5,2,\n",
      "18,70,5,2,,01 Feb,72,8,3,\n",
      "19,70,5,2,,,,,,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file1 = open(f[0], 'r')\n",
    "print(file1.read())\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20c34422",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 May 0749,WATCH: Geomagnetic Storm Category G2 predicted,\n",
      "24 May 1812,ALERT: Electron 2MeV Integral Flux >= 1000pfu,24/1805\n",
      "25 May 1243,\"CONTINUED ALERT:\n",
      "Electron 2MeV Integral Flux >= 1000pfu\",24/1805\n",
      "26 May 1203,WARNING: Geomagnetic Sudden Impulse expected,26/1250 - 1330\n",
      "26 May 1318,SUMMARY: Geomagnetic Sudden Impulse,26/1252\n",
      "26 May 1621,WARNING: Geomagnetic K = 4,26/1625 - 2359\n",
      "26 May 1622,\"CONTINUED ALERT:\n",
      "Electron 2MeV Integral Flux >= 1000pfu\",24/1805\n",
      "26 May 1821,EXTENDED WARNING: Geomagnetic K = 4,26/1625 - 27/0559\n",
      "26 May 1822,WARNING: Geomagnetic K = 5,26/1825 - 2359\n",
      "26 May 1830,ALERT: Geomagnetic K = 4,26/1828\n",
      "26 May 2028,ALERT: Geomagnetic K = 5,26/2028\n",
      "27 May 0244,EXTENDED WARNING: Geomagnetic K = 4,26/1625 - 27/1200\n",
      "27 May 0245,WARNING: Geomagnetic K = 5,27/0244 - 0900\n",
      "29 May 0024,ALERT: Type II Radio Emission,28/2303\n",
      "29 May 0025,ALERT: Type IV Radio Emission,28/2301\n",
      "29 May 0043,WARNING: Proton 10MeV Integral Flux > 10pfu,29/0042 - 1200\n",
      "29 May 0319,ALERT: Proton Event 10MeV Integral Flux >= 10pfu,29/0300\n",
      "29 May 0831,SUMMARY: Proton Event 10MeV Integral Flux >= 10pfu,29/0300 - 0540\n",
      "29 May 0835,\"CANCELLATION:\n",
      "Proton 10MeV Integral Flux > 10pfu\",\n",
      "29 May 0836,\"CANCELLATION:\n",
      "Proton Event 10MeV Integral Flux >= 10pfu\",\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file2 = open(f[1], 'r')\n",
    "print(file2.read())\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89c7801",
   "metadata": {},
   "source": [
    "In some instances the table of interest appears on page 5 (not 4). Continue to run the notebook to resolve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ab3bff35",
   "metadata": {},
   "outputs": [],
   "source": [
    "readfiles =[]\n",
    "for txtfile in f:\n",
    "    file = open(txtfile, 'r')\n",
    "    readfiles.append(file.read())\n",
    "    file.close()\n",
    "# readfiles ## will preview all converted text files as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "193b2389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'06 Jan,72,12,4,,20 Jan,70,5,2,\\n07,72,5,2,,21,70,5,2,\\n08,72,8,3,,22,70,5,2,\\n09,72,8,3,,23,70,5,2,\\n10,72,8,3,,24,70,5,2,\\n11,72,5,2,,25,71,5,2,\\n12,71,5,2,,26,72,5,2,\\n13,70,5,2,,27,72,5,2,\\n14,70,12,4,,28,72,5,2,\\n15,70,12,4,,29,72,5,2,\\n16,70,5,2,,30,72,5,2,\\n17,70,5,2,,31,72,5,2,\\n18,70,5,2,,01 Feb,72,8,3,\\n19,70,5,2,,,,,,\\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "readfiles[0] # preview a select file by element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e7d771bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "317"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(readfiles[0]) # a correct table will have about 300 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "43f4d667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1247"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(readfiles[1]) # an incorrect table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edde0532",
   "metadata": {},
   "source": [
    "If length of file has more than 350 characters, it is likely the wrong table. We can use that as a filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "11b558f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered =[]\n",
    "\n",
    "for s in range(len(readfiles)):\n",
    "    if (len(readfiles[s]) > 350):\n",
    "        filtered.append(s)\n",
    "filtered = [int(i) for i in filtered] # these are the incorrect files corresponding to the element in the list. \n",
    "filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6f0d3f",
   "metadata": {},
   "source": [
    "Here are the filenames that need to be re-processed with the correct page number using the convert_into function. More than likely this will be page 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "181928d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2387.txt']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil = [] # locating the filename of the PDF with the problem\n",
    "for val in filtered:\n",
    "    fil.append(ls[val])\n",
    "fil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816ce397",
   "metadata": {},
   "source": [
    "Delete the incorrect text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0d5bf33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for txtfile in fil:\n",
    "    os.remove(txtfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "56292fc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The bad text files were successfully deleted\n"
     ]
    }
   ],
   "source": [
    "txt_ls = []\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "     txt_ls.append(file)\n",
    "\n",
    "num_txt = len(txt_ls)\n",
    "\n",
    "num_txt = len(glob.glob1(directory,\"*.txt\"))\n",
    "\n",
    "if num_pdfs == num_txt:\n",
    "    print(\"Try again\")\n",
    "else: \n",
    "    print(\"The bad text files were successfully deleted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a4817a",
   "metadata": {},
   "source": [
    "Rerun the conversion for these PDF files but on page 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cc737e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2387.txt']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a new list of output_filenames from PDF filenames in dir but with .txt extension\n",
    "\n",
    "fil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3fb6ce7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2387.txt'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fil[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1a479eba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/john.mayers/Documents/27_Day/Data/2020_23_WeeklyPDF/prf2387.pdf']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating a new list of input_filenames\n",
    "\n",
    "input_new=[]\n",
    "\n",
    "for file in range(len(fil)):\n",
    "    split = os.path.splitext(fil[file])\n",
    "    input_new.append(split[file] + \".pdf\")\n",
    "input_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d1d28860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 61/61 [00:43<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "for pdf in tqdm(directory):\n",
    "    for i in range(len(fil)):\n",
    "        convert_into(input_new[i], fil[i], pages=5) #iterating through input and output filenames from lists above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "3d45d5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "readfiles =[]\n",
    "for txtfile in f:\n",
    "    file = open(txtfile, 'r')\n",
    "    readfiles.append(file.read())\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "24fd62e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tables are correct.\n"
     ]
    }
   ],
   "source": [
    "filtered =[]\n",
    "\n",
    "for ele in range(len(fil)):\n",
    "    if (len(readfiles[ele]) > 350):\n",
    "        filtered.append(ele)\n",
    "\n",
    "        filtered = [int(i) for i in filtered] # these are the incorrect files corresponding to the element in the list. \n",
    "    \n",
    "    if len(filtered) == 0:\n",
    "        print(\"All tables are correct.\")\n",
    "    else:\n",
    "        print(f'The table from {filtered} is incorrect.')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "26a5f5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>06 Jan</th>\n",
       "      <th>72</th>\n",
       "      <th>12</th>\n",
       "      <th>4</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>20 Jan</th>\n",
       "      <th>70</th>\n",
       "      <th>5</th>\n",
       "      <th>2</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31 May</td>\n",
       "      <td>72</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14 Jun</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01 Jun</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>78.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>02</td>\n",
       "      <td>72</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16</td>\n",
       "      <td>80.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24</td>\n",
       "      <td>70.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>03</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17</td>\n",
       "      <td>80.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25</td>\n",
       "      <td>71.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>04</td>\n",
       "      <td>72</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18</td>\n",
       "      <td>80.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   06 Jan    72   12    4  Unnamed: 4 20 Jan    70    5    2  Unnamed: 9  \\\n",
       "0     7.0  72.0  5.0  2.0         NaN     21  70.0  5.0  2.0         NaN   \n",
       "1     8.0  72.0  8.0  3.0         NaN     22  70.0  5.0  2.0         NaN   \n",
       "2     9.0  72.0  8.0  3.0         NaN     23  70.0  5.0  2.0         NaN   \n",
       "3    10.0  72.0  8.0  3.0         NaN     24  70.0  5.0  2.0         NaN   \n",
       "4    11.0  72.0  5.0  2.0         NaN     25  71.0  5.0  2.0         NaN   \n",
       "\n",
       "        0   1   2  3   4       5     6     7    8   9  \n",
       "0  31 May  72   5  2 NaN  14 Jun  78.0   5.0  2.0 NaN  \n",
       "1  01 Jun  72  18  4 NaN      15  78.0   5.0  2.0 NaN  \n",
       "2      02  72  15  4 NaN      16  80.0  20.0  5.0 NaN  \n",
       "3      03  72   8  3 NaN      17  80.0  10.0  3.0 NaN  \n",
       "4      04  72   8  3 NaN      18  80.0   5.0  2.0 NaN  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main_df = pd.DataFrame(pd.read_csv(f[0])) # this cell will not run if there is an issue with the text files\n",
    "  \n",
    "for i in range(1,len(f)):\n",
    "    data = pd.read_csv(f[i],header=None)\n",
    "    df = pd.DataFrame(data)\n",
    "    main_df = pd.concat([main_df,df], axis=1)\n",
    "main_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e43cc3",
   "metadata": {},
   "source": [
    "<h3>Cleaning the Data for Analysis</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6a7568",
   "metadata": {},
   "source": [
    "<h4>Understanding the table structure</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c0be73",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_copy = main_df.copy() # make a copy of the df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673bd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'This table has {main_copy.shape[0]} rows and {main_copy.shape[1]} columns.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066989f1",
   "metadata": {},
   "source": [
    "<h4>Looking at a subset of the table corresponding to the first forecast</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8641d2a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pdf1 = main_copy.iloc[:,0:10] #looking at the cols corresponding to the first PDF. Each PDF has 10 cols.\n",
    "pdf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44a1405",
   "metadata": {},
   "source": [
    "<h4>Fixing col lables</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505d6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04e1cd5",
   "metadata": {},
   "source": [
    "Every 5th col needs to be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e4aec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = main_copy.loc[:, (np.arange(len(main_copy.columns)) + 1) % 5 != 0]\n",
    "main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e25f6f",
   "metadata": {},
   "source": [
    "Creating a list of lists that repeats col labels based on the number of tables in the main df, then flattening that list of lists into a large list to pass into the df as the new col labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8d715f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cols = [['Date', 'Radio', 'Ap', 'Kp', 'Date', 'Radio', 'Ap', 'Kp']] \n",
    "\n",
    "k=int(len(main.columns)/8)\n",
    "\n",
    "res = [ele for ele in new_cols for i in range(k)] #list of lists of col headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69875d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in res for item in sublist] # flattening into 1 large list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d263c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(main.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20ffcf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = main.columns # to be transferred into first row\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f25a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.loc[-1] = row # adding a row and setting it to row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb50a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.index = main.index + 1 #shifting index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2945102a",
   "metadata": {},
   "outputs": [],
   "source": [
    "main = main.sort_index() # sorting by index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c8a2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.columns = flat_list # setting new col labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8270fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7f5614",
   "metadata": {},
   "source": [
    "<h3>Inspecting individual forecasts from main df</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aa41dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.iloc[:,0:8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e815be",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.iloc[:,8:16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1881232",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.iloc[:,16:24]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b958e6",
   "metadata": {},
   "source": [
    "Starting with col9, all values in row0 should be set to Nan. All these values should be replaced with NaN. They are erroneous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8352f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.iloc[:1,8:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61accae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.iloc[:1,8:] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b2e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "main.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1652fa5e",
   "metadata": {},
   "source": [
    "<h3>Cleaning up dates</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9967c0",
   "metadata": {},
   "source": [
    "The dates present a problem, since only the first date is printed, followed by the day only, until the next col or if the month changes before then."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ac0d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "main['Date']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc229356",
   "metadata": {},
   "source": [
    "In the first forecast, the start date is row0, col1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499740f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = main['Date'].iloc[0:1,:1]\n",
    "c1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d18abf2",
   "metadata": {},
   "source": [
    "In the second forecast, and all following, the start date is row1, co12, col4, col6, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7c6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1 = main['Date'].iloc[1:2,2:3]\n",
    "d1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb8b6f",
   "metadata": {},
   "source": [
    "<h3>Building a new df with dates and F10 forecasts</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e5b62e",
   "metadata": {},
   "source": [
    "In order to avoid some tricky programming to fill in the table, the approach will be to populate 27 days lists beginning with the start time of each forecast. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02b012f",
   "metadata": {},
   "source": [
    "<h4>Extracting start times</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56390550",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2 = pd.DataFrame(data=c1)\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af7006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_ls = c2['Date'].tolist()\n",
    "c2_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c2_ls.append('2020')\n",
    "c2_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "131d9487",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = c2_ls[0] + ' ' + c2_ls[1]\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c84c2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "format ='%d %b %Y'\n",
    "dt = datetime.strptime(start, format).date() #start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a9bba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27\n",
    " \n",
    "res = []\n",
    " \n",
    "for day in range(k):\n",
    "    date = (dt + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eb65419",
   "metadata": {},
   "source": [
    "<h4>Using Regex to find entries with months in dataframe</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1da3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a5b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "from re import match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14935f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = main['Date'].iloc[:,0:1].values.tolist()\n",
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4d6b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "regex = r\"((\\d+) [a-zA-Z]+)\" # matches day and 3-digit month df\n",
    "regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c09d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list1 = [item for sublist in ls for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a942c57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = [item for item in flat_list1 if not(pd.isnull(item)) == True] # removing nan in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147ee0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list1 = [str(i) for i in new_list] # converting each element to a string\n",
    "new_list1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1e189",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e =list(filter(lambda x: match(regex, x), new_list1))\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29026e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.append('2020')\n",
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788cadea",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = e[0] + ' ' + e[1]\n",
    "start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c889cd4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "format ='%d %b %Y'\n",
    "dt = datetime.strptime(start, format).date() #start date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7f6faa",
   "metadata": {},
   "source": [
    "<h4>With initial start date, populating 1st forecast dates</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9037cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27\n",
    " \n",
    "res = []\n",
    " \n",
    "for day in range(k):\n",
    "    date = (dt + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)\n",
    "res[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb0119f",
   "metadata": {},
   "source": [
    "So need to extract each forecast's start date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa3f763",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27\n",
    " \n",
    "date1 = []\n",
    " \n",
    "for day in range(k):\n",
    "    date = (dt + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    date1.append(date)\n",
    "date1[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470fa100",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin = date1[0]\n",
    "begin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d74e019",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Begindate = datetime.strptime(begin, \"%d %b %Y\")\n",
    "Begindate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893cccf0",
   "metadata": {},
   "source": [
    "<h4>Manually calculating forecast start times from pattern</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88823814",
   "metadata": {},
   "source": [
    "Pattern: Each successive forecast increases by 7 days from the previous forecast or n times 7 from the first forecast where n is the number of forecasts from the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95c37be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Begindate2 = Begindate + timedelta(days=7)\n",
    "Begindate2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f394e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "Begindate3 = Begindate + timedelta(days=14)\n",
    "Begindate3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b6c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Begindate4 = Begindate + timedelta(days=21)\n",
    "Begindate4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744fa810",
   "metadata": {},
   "outputs": [],
   "source": [
    "Begindate5 = Begindate + timedelta(days=28)\n",
    "Begindate5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b70e0c",
   "metadata": {},
   "source": [
    "<h4> Automatically calculating start times for n forecasts</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6ce4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate the number of forecasts\n",
    "Begindate = datetime.strptime(begin, \"%d %b %Y\")\n",
    "mult = list(range(0,num_pdfs*7,7))\n",
    "mult = mult[1:]\n",
    "\n",
    "for j in mult: #multiples of 7 starting with 7\n",
    "    x = Begindate + timedelta(days=j)\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175ef59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#iterate the number of forecasts\n",
    "Begindate = datetime.strptime(begin, \"%d %b %Y\")\n",
    "mult = list(range(0,num_pdfs*7,7)) #multiples of 7 \n",
    "mult = mult[1:] #multiples of 7 starting with 7\n",
    "\n",
    "ls=[]\n",
    "\n",
    "for j in mult:\n",
    "    x = Begindate + timedelta(days=j)\n",
    "    ls.append(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af4c4db",
   "metadata": {},
   "source": [
    "<h4>List of dates corresponding to 2nd forecast</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f1c42c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27\n",
    " \n",
    "res = []\n",
    " \n",
    "for day in range(k):\n",
    "    date = (ls[0] + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d3b708",
   "metadata": {},
   "source": [
    "<h4>List of dates corresponding to 3rd forecast</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b5d1da",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27\n",
    " \n",
    "res = []\n",
    " \n",
    "for day in range(k):\n",
    "    date = (ls[1] + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e062c9",
   "metadata": {},
   "source": [
    "<h4> Manually compiling all forecast dates into a list</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d0e4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27\n",
    " \n",
    "res = []\n",
    "\n",
    "format ='%d %b %Y'\n",
    "dt = datetime.strptime(start, format).date() \n",
    " \n",
    "for day in range(k):\n",
    "    date = (dt + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)\n",
    "    \n",
    "res\n",
    " \n",
    "for day in range(k):\n",
    "    date = (ls[0] + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)\n",
    "res\n",
    "\n",
    "\n",
    "for day in range(k):\n",
    "    date = (ls[1] + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)\n",
    "res\n",
    "\n",
    "for day in range(k):\n",
    "    date = (ls[2] + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)\n",
    "res\n",
    "\n",
    "for day in range(k):\n",
    "    date = (ls[3] + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c056957",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41923fcb",
   "metadata": {},
   "source": [
    "<h4>Automatically compile n forecast dates into a list</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b686fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27 #iterates through all elements of ls to append dates in correct order\n",
    "\n",
    "res2=[]\n",
    "\n",
    "for i in range(len(ls)):\n",
    "    for day in range(k):\n",
    "        date = (ls[i] + timedelta(days = day))\n",
    "        date = date.strftime('%d %b %Y')\n",
    "        res2.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2952d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(res2)} dates. Recall the first forecast is missing.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351da80a",
   "metadata": {},
   "source": [
    "<h4>Adding in first forecast to list</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29aaac4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 27 #now let's append the first forecast \n",
    "\n",
    "res11 = []\n",
    " \n",
    "for day in range(k):\n",
    "    date = (dt + timedelta(days = day))\n",
    "    date = date.strftime('%d %b %Y')\n",
    "    res11.append(date)\n",
    "\n",
    "for i in range(len(ls)):\n",
    "    for day in range(k):\n",
    "        date = (ls[i] + timedelta(days = day))\n",
    "        date = date.strftime('%d %b %Y')\n",
    "        res11.append(date)\n",
    "res11[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7175cad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'There are {len(res11)} dates corresponding to {num_pdfs*27} rows from {num_pdfs} forecasts.') #matches number of forecasts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2049cbc5",
   "metadata": {},
   "source": [
    "<h4>Extracting F10 forecast values from the main df and creating a new df</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e2a08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_wide = main['Radio']\n",
    "f10_wide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d08403c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_long_nan = f10_wide.melt()\n",
    "f10_long_nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e88a849",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_long = f10_long_nan.dropna(axis=0) # delete all rows with nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4c8b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_long = f10_long.drop(['variable'], axis=1)\n",
    "f10_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171f4f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_long = f10_long.rename(columns={\"value\": \"Kp\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480fe428",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_long = f10_long.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d88f9ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10_long = f10_long.drop(['index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff73f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(res11, columns=['res']) #res11 (dates) needs to be transformed into a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf67f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = final_df.rename(columns={\"res\": \"Date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68100e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['Radio'] = f10_long"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12568d7e",
   "metadata": {},
   "source": [
    "<h4>The final table that observed F10 can be added to for analysis</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d41524",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.head(32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd1d1ada",
   "metadata": {},
   "source": [
    "Above you can see that the after Feb 1, the date does not continue with 2 Feb, but with 13 Feb, which is the starting date in the next forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c1c054",
   "metadata": {},
   "source": [
    "<h3>Importing Observed F10 Data</h3><br/>\n",
    "Observed F10.7 from Government of Canada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9870e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10obs = pd.read_excel('C:/Users/john.mayers/Documents/27_Day/Data/noon_flux2020.xlsx')\n",
    "f10obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e0e5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10obs = f10obs[['Date.1','Noon Flux']] \n",
    "f10obs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745358d1",
   "metadata": {},
   "source": [
    "<h3>Matching observed F10 with forecast F10</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fda4019",
   "metadata": {},
   "source": [
    "<h4>Creating a subset of obs that match up to the days corresponding to the n forecasts</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d9c32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Begindate + timedelta(days=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b00f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10obs.iloc[5:27+5,0:2] # obs corresponding forecast 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d7670",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f10obs.iloc[12:12+27,0:2] # obs corresponding to forecast 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295184cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "f10obs.iloc[19:19+27,0:2] # obs corresponding to forecast 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad25cea",
   "metadata": {},
   "source": [
    "<h4> Writing a loop to populate a list of obs corresponding to forecast dates </h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e6d413",
   "metadata": {},
   "source": [
    "The pattern emerges... 7 gets added each iteration to the start and end position of the row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ddc8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range(0,num_pdfs*7,7)) # recalling multiples of 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d605f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =[]\n",
    "\n",
    "for i in range(0,num_pdfs*7,7):\n",
    "    r = f10obs.iloc[5 + (i):5 +(i) +27,0:2]\n",
    "    dates.append(r)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844ef2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates =[] \n",
    "\n",
    "for i in range(0,num_pdfs*7,7):\n",
    "    r = f10obs.iloc[5 + (i):5 +(i) +27,1:2] # just the values without dates\n",
    "    dates.append(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a3e700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f'This \"pandas list\" has {len(dates)} elements but we need {num_pdfs *27 }, so we will flatten the list.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde3ba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates[0].values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf561f13",
   "metadata": {},
   "source": [
    "Interating through each pandas list to convert to a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e4b326",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll=[]\n",
    "\n",
    "for l in range(num_pdfs):\n",
    "    a = dates[l].values.tolist()\n",
    "    ll.append(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "160b0fae",
   "metadata": {},
   "source": [
    "Flattening the list twice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ab1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat=[]\n",
    "\n",
    "for sublist in ll:\n",
    "    for element in sublist:\n",
    "        flat.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6814e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat2=[]\n",
    "\n",
    "for sublist in flat:\n",
    "    for element in sublist:\n",
    "        flat2.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ece2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are now {len(flat2)} observed values corresponding to {num_pdfs*27} forecasts in the correct order which can now be merged into 1 df.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a619b6",
   "metadata": {},
   "source": [
    "<h4>Final Merge</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcf24be",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = final_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780aa981",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.rename(columns={\"Kp\": \"Forecast Kp\"})\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2da720",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "complete_df['Observed F10'] = flat2\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0331385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df = complete_df.rename(columns={\"Radio\": \"Forecast F10\"})\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bdb7d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rounding Observed Kp to nearest integer\n",
    "\n",
    "complete_df['Observed F10'] = complete_df['Observed F10'].round()\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09041973",
   "metadata": {},
   "source": [
    "<h3>Final Table for Analysis</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e9ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.dropna(how=\"any\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715d5872",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['Forecast F10']= complete_df['Forecast F10'].astype('int')\n",
    "complete_df['Observed F10']= complete_df['Observed F10'].astype('int')\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae144c3e",
   "metadata": {},
   "source": [
    "<h3>Forecast Performance</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8454c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df[\"Forecast Error\"] = complete_df[\"Forecast F10\"] - complete_df[\"Observed F10\"] \n",
    "complete_df.head()\n",
    "\n",
    "# negative under forecast\n",
    "# positive over forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd23d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df['Abs Error'] = complete_df['Forecast Error'].abs()\n",
    "complete_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f2fda9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "last = final_df['Date'].iloc[-1]\n",
    "\n",
    "print(f'For the {num_pdfs} forecasts, beginning on {begin} and ending on {last}, the average forecast error was {sum(complete_df[\"Abs Error\"])/len(complete_df)} sfu.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac2ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = sum(complete_df[\"Forecast Error\"])/len(complete_df)\n",
    "y=abs(x)\n",
    "\n",
    "if sum(complete_df[\"Forecast Error\"])/len(complete_df) < 0:\n",
    "    print(f'On average, F10 was underforecast by {x}.')\n",
    "    \n",
    "else:\n",
    "    print(f'On average, F10 was overforecast by {y}.')\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407e328f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_err = complete_df[['Abs Error']].max().tolist()\n",
    "print(f' The max forecast error was {max_err} sfu.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fde07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count5 = complete_df['Abs Error'][complete_df['Abs Error'] > 5].count()\n",
    "count10 = complete_df['Abs Error'][complete_df['Abs Error'] > 10].count()\n",
    "count20 = complete_df['Abs Error'][complete_df['Abs Error'] > 20].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0a9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'The forecast was off by more the 5 sfu {count5} times, 10 sfu {count10} times and more than 20 sfu, {count20} times.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb45bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "perfect = complete_df['Forecast Error'].value_counts()[0]\n",
    "print(f'The forecast was still perfect {perfect} times or {perfect/len(complete_df) * 100} percent of the time.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dedb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1e2041",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = complete_df['Abs Error'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c50982",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(freq.index, freq.values)\n",
    "\n",
    "plt.xlabel(\"Forecast Error\", size=10)\n",
    "plt.ylabel(\"Frequency\", size=10)\n",
    "plt.title(\"Frequency and Magnitude of Errors for F10\", size=15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42556eab",
   "metadata": {},
   "source": [
    "<h4> Fitting a Regression </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d52e0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = Ridge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e4fa37",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=complete_df['Date']\n",
    "X_axis=np.arange(len(X))\n",
    "lr.fit(X_axis.reshape(-1,1), complete_df['Abs Error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af06f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "figure(figsize=(70, 40), dpi=100)\n",
    "\n",
    "plt.bar(X_axis, complete_df['Abs Error'])\n",
    "plt.plot(X_axis, lr.coef_*X_axis+lr.intercept_, color='red', linewidth=20)\n",
    "\n",
    "plt.xticks(fontsize=40)\n",
    "plt.yticks(fontsize=40)\n",
    "\n",
    "\n",
    "plt.xlabel(\"Days\", size=50)\n",
    "plt.ylabel(\"F10 Error\", size=50)\n",
    "plt.title(\"Daily F10.7 Forecast Errors for [test_data]\",fontsize=75)\n",
    "plt.legend(['Trend'], fontsize=50)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "color = 'tab:blue'\n",
    "ax1.set_xlabel('Days')\n",
    "ax1.set_ylabel('Observed F10.7', color=color)\n",
    "ax1.plot(X_axis, complete_df['Observed F10'], color=color, linewidth=2)\n",
    "ax1.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "color = 'tab:red'\n",
    "ax2.set_ylabel('F10.7 Forecast Error', color=color)\n",
    "ax2.bar(X_axis, complete_df['Abs Error'], color=color, alpha=0.25)\n",
    "ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "plt.title(\"Comparison of Observed F10.7 with Forecast Errors for [test_data]\",fontsize=20)\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee82aead",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize =(6, 5))\n",
    "plt.boxplot(complete_df['Forecast Error'])\n",
    "\n",
    "\n",
    "plt.ylabel(\" Error\", size=10)\n",
    "plt.title(\"F10.7 Forecast Error for [test_data]\",fontsize=15)\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef8ceab",
   "metadata": {},
   "source": [
    "<h4>Mean Absolute Percentage Error</h4>\n",
    "Definition: The absolute value of the difference between the forecasted value and the actual value taken as a mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78c6a62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "actual   = complete_df['Observed F10']\n",
    "forecast = complete_df['Forecast F10']\n",
    "  \n",
    "APE = [] # percentage error between the forecast and observed value\n",
    "  \n",
    "for day in range(len(actual)):\n",
    "    per_err = (actual[day] - forecast[day]) / actual[day]\n",
    "    per_err = abs(per_err)\n",
    "    APE.append(per_err)\n",
    "  \n",
    "MAPE = sum(APE)/len(APE)\n",
    "\n",
    "print(f'''\n",
    "MAPE   : { round(MAPE, 2) }\n",
    "MAPE % : { round(MAPE*100, 2) } %\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eee3bb1",
   "metadata": {},
   "source": [
    "<h4> Accuracy (POD) </h4>\n",
    "Definition: How many times the forecast was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f33532",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC = perfect/len(actual)\n",
    "ACC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e724a94c",
   "metadata": {},
   "source": [
    "<h4> False Alarm Ratio (FAR) </h4>\n",
    "Definition: How many times the forecast was wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e057dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FAR = (len(complete_df['Forecast F10'])-perfect) / len(complete_df['Forecast F10'])\n",
    "FAR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b8b7bb8",
   "metadata": {},
   "source": [
    "*Note: POD and FAR are typically used for categorical data rather than discrete data such as integers. The definitions of both have been applied libearlly in order to compute these values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ead8897",
   "metadata": {},
   "source": [
    "<h4> Heidke Skill Score </h4>\n",
    "Compares the accuracy of the forecasts against the accuracy of some reference model (coefficient of determination), normalized by a perfect model score of 1 against the same coefficient of determination."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a1a81d",
   "metadata": {},
   "source": [
    "In order to create a \"skill score\" we need to create a reference model based on the observed data points and determine its accuracy (Aref). A linear regression model \"trend line\" through all observed values will serve as a first guess model for this demonstration. Future efforts should be made to fit a more accurate model in order to extract more meaningful value from a skill score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0944613e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lr.fit(X_axis.reshape(-1,1), complete_df['Observed F10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf86a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(X_axis.reshape(-1,1), complete_df['Observed F10'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42813517",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_sq = model.score(X_axis.reshape(-1,1), complete_df['Abs Error'])\n",
    "r_sq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0c7b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Aperf = 1\n",
    "Aref = r_sq\n",
    "\n",
    "SS = (ACC - Aref)/(Aperf-Aref) # skill score formula\n",
    "SS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7703e98f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SS == 1:\n",
    "    print(\"The forecast is perfect\")\n",
    "elif SS > 0:\n",
    "    print(\"The forecast is skillful and better than some reference.\")\n",
    "else:\n",
    "    print(\"The forecast is less skillful than some reference.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cbcb85",
   "metadata": {},
   "source": [
    "Now let's define a good forecast as an error no greater than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd203d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Recall there are {count5} forecasts with errors greater than 5.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b50765",
   "metadata": {},
   "source": [
    "And we will define an accuracy below 70% as a bad forecast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50e69a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ACC5 = (len(actual)-count5)/len(actual)\n",
    "\n",
    "if ACC5 == 1:\n",
    "    print(f'The forecasts are perfect with an overall accuracy of {ACC5*100}%.')\n",
    "elif ACC5 > .7:\n",
    "    print(f'The forecasts are good with an overall accuracy of {ACC5*100}%.')\n",
    "else:\n",
    "    print(f'The forecasts are bad with an overall accuracy of {ACC5*100}%.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7fb5634",
   "metadata": {},
   "source": [
    "<h3>Conclusions</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc43c93",
   "metadata": {},
   "source": [
    "This notebook successfully demonstrates proof of concept in assessing the accuracy of 27 Day F10.7 Forecasts using a test dataset. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
